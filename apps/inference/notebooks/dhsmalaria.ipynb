{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "26eb6ad7",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# File Path\n",
                "dhs_path = \"data_private/dhs/india/raw/IAKR7EFL.DTA\"\n",
                "\n",
                "# Feature Mapping (New Name: DHS Original Name)\n",
                "FEATURE_COLUMNS = {\n",
                "    \"fever\": \"h22\",                 # Fever in last 2 weeks\n",
                "    \"age_months\": \"b19\",           # Child age in months\n",
                "    \"state\": \"v024\",              # State\n",
                "    \"residence_type\": \"v025\",     # Urban / Rural\n",
                "    \"slept_under_net\": \"ml0\",     # ITN usage\n",
                "    \"anemia_level\": \"hw57\",       # Anemia severity (proxy risk)\n",
                "    \"interview_month\": \"v006\"     # Seasonality signal\n",
                "}\n",
                "\n",
                "chunk_size = 50000"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "6f6f550f",
            "metadata": {},
            "outputs": [],
            "source": [
                "chunks = []\n",
                "\n",
                "# Use only required columns to save memory\n",
                "required_cols = list(FEATURE_COLUMNS.values())\n",
                "rename_map = {v: k for k, v in FEATURE_COLUMNS.items()}\n",
                "\n",
                "print(f\"Reading {dhs_path} in chunks of {chunk_size}...\")\n",
                "\n",
                "try:\n",
                "    with pd.read_stata(\n",
                "        dhs_path,\n",
                "        columns=required_cols,\n",
                "        convert_categoricals=False,\n",
                "        iterator=True,\n",
                "        chunksize=chunk_size\n",
                "    ) as reader:\n",
                "        \n",
                "        for i, chunk in enumerate(reader):\n",
                "            # Rename columns to friendly names\n",
                "            chunk = chunk.rename(columns=rename_map)\n",
                "            \n",
                "            # Drop rows where ALL symptom indicators are missing (NaN)\n",
                "            # Updated Symptoms: fever only, as current_fever and convulsions are removed\n",
                "            symptoms = [\"fever\"]\n",
                "            chunk = chunk.dropna(subset=symptoms, how='all')\n",
                "            \n",
                "            chunks.append(chunk)\n",
                "            print(f\"Processed Chunk {i+1}: {chunk.shape[0]} rows kept\")\n",
                "\n",
                "    # Concatenate all chunks\n",
                "    symptom_df = pd.concat(chunks, ignore_index=True)\n",
                "\n",
                "    print(\"\\n--- Processing Complete ---\")\n",
                "    print(f\"Final Data Shape: {symptom_df.shape}\")\n",
                "\n",
                "    print(\"\\n% Missing Values per Column:\")\n",
                "    print((symptom_df.isnull().sum() / len(symptom_df) * 100).round(2))\n",
                "\n",
                "    print(\"\\nValue Counts: Fever (Last 2 Weeks)\")\n",
                "    print(symptom_df['fever'].value_counts(dropna=False))\n",
                "\n",
                "except FileNotFoundError:\n",
                "    print(f\"Error: The file {dhs_path} was not found.\")\n",
                "except ValueError as ve:\n",
                "    print(f\"ValueError: {ve}\")\n",
                "except Exception as e:\n",
                "    import traceback\n",
                "    traceback.print_exc()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "e0e3b9f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copy to avoid modifying original extraction\n",
                "risk_df = symptom_df.copy()\n",
                "\n",
                "# 1. Clean DHS Keys (8 = Don't Know -> NaN)\n",
                "risk_df['fever'] = risk_df['fever'].replace(8, np.nan)\n",
                "risk_df['slept_under_net'] = risk_df['slept_under_net'].replace(8, np.nan)\n",
                "\n",
                "# 2. Rule-Based Labeling\n",
                "# Default Risk = 0 (Low)\n",
                "risk_df['malaria_risk'] = 0\n",
                "\n",
                "# Helpers masks\n",
                "has_fever = (risk_df['fever'] == 1)\n",
                "used_net = (risk_df['slept_under_net'] == 1)\n",
                "no_net = (risk_df['slept_under_net'] == 0) | (risk_df['slept_under_net'].isna())\n",
                "\n",
                "# IMPORTANT: DHS Anemia Levels (hw57)\n",
                "# 1 = Severe, 2 = Moderate, 3 = Mild, 4 = Not Anemic\n",
                "# We target Moderate/Severe (1 or 2)\n",
                "severe_anemia = risk_df['anemia_level'].isin([1, 2])\n",
                "\n",
                "# Rule: Fever == 1 AND Net == 1 -> Medium Risk (1)\n",
                "risk_df.loc[has_fever & used_net, 'malaria_risk'] = 1\n",
                "\n",
                "# Rule: Fever == 1 AND No Net (or missing) -> High Risk (2)\n",
                "risk_df.loc[has_fever & no_net, 'malaria_risk'] = 2\n",
                "\n",
                "# Rule: Fever == 1 AND Moderate/Severe Anemia -> Force High Risk (2)\n",
                "risk_df.loc[has_fever & severe_anemia, 'malaria_risk'] = 2\n",
                "\n",
                "# 3. Validation Output\n",
                "print(\"Malaria Risk Distribution:\")\n",
                "print(risk_df['malaria_risk'].value_counts(dropna=False).sort_index())\n",
                "\n",
                "print(\"\\nCross-tab: Fever vs Malaria Risk\")\n",
                "print(pd.crosstab(risk_df['fever'].fillna(\"Missing\"), risk_df['malaria_risk']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "ml_training_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "\n",
                "# --- 1. Data Cleaning & Encoding ---\n",
                "model_df = risk_df.copy()\n",
                "\n",
                "# Clean '8' (Don't Know) in other features if present (anemia explicitly mentioned in prompt)\n",
                "# DHS Anemia (hw57) usually doesn't have 8, but we'll safeguard.\n",
                "model_df['anemia_level'] = model_df['anemia_level'].replace(8, np.nan)\n",
                "\n",
                "# Impute Missing Values\n",
                "# We strictly replace missing values with a placeholder (-1) so the model sees them.\n",
                "# Dropping rows might lose 'High Risk' cases where features were missing but rule applied.\n",
                "imputer = SimpleImputer(strategy='constant', fill_value=-1)\n",
                "cols_to_impute = ['fever', 'age_months', 'slept_under_net', 'anemia_level', 'interview_month']\n",
                "model_df[cols_to_impute] = imputer.fit_transform(model_df[cols_to_impute])\n",
                "\n",
                "# Encode Categoricals (State, Residence)\n",
                "# Ensure string type for LabelEncoder\n",
                "le_state = LabelEncoder()\n",
                "model_df['state'] = le_state.fit_transform(model_df['state'].astype(str))\n",
                "\n",
                "le_res = LabelEncoder()\n",
                "model_df['residence_type'] = le_res.fit_transform(model_df['residence_type'].astype(str))\n",
                "\n",
                "# --- 2. Split Data ---\n",
                "X = model_df[['fever', 'age_months', 'state', 'residence_type', 'slept_under_net', 'anemia_level', 'interview_month']]\n",
                "y = model_df['malaria_risk']\n",
                "\n",
                "# Stratified 80/20 split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
                "\n",
                "# --- 3. Train Model ---\n",
                "print(\"Training RandomForestClassifier...\")\n",
                "rf_model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
                "rf_model.fit(X_train, y_train)\n",
                "\n",
                "# --- 4. Evaluate ---\n",
                "y_pred = rf_model.predict(X_test)\n",
                "\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred, target_names=['Low', 'Medium', 'High']))\n",
                "\n",
                "print(\"Confusion Matrix:\")\n",
                "print(confusion_matrix(y_test, y_pred))\n",
                "\n",
                "# --- 5. Feature Importance ---\n",
                "print(\"\\nFeature Importance Ranking:\")\n",
                "importance_df = pd.DataFrame({\n",
                "    'Feature': X.columns,\n",
                "    'Importance': rf_model.feature_importances_\n",
                "}).sort_values(by='Importance', ascending=False)\n",
                "\n",
                "print(importance_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "save_model_cell",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Model and preprocessors saved to apps/inference/models/malaria_symptoms_dhs.pkl\n"
                    ]
                }
            ],
            "source": [
                "import joblib\n",
                "import os\n",
                "\n",
                "# Create directory if it doesn't exist\n",
                "os.makedirs(\"apps/inference/models\", exist_ok=True)\n",
                "\n",
                "# Bundle the model and preprocessors\n",
                "model_bundle = {\n",
                "    \"model\": rf_model,\n",
                "    \"imputer\": imputer,\n",
                "    \"le_state\": le_state,\n",
                "    \"le_res\": le_res,\n",
                "    \"features\": ['fever', 'age_months', 'state', 'residence_type', 'slept_under_net', 'anemia_level', 'interview_month'],\n",
                "    \"cols_to_impute\": cols_to_impute\n",
                "}\n",
                "\n",
                "save_path = \"apps/inference/models/malaria_symptoms_dhs.pkl\"\n",
                "joblib.dump(model_bundle, save_path)\n",
                "\n",
                "print(f\"✅ Model and preprocessors saved to {save_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
